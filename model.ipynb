{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 10\n",
    "GRAYSCALE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='data',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the implementation here\n",
    "\n",
    "https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "    )\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True) # inplace=True means that it will modify the input directly, without allocating any additional output\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual # skip \n",
    "        out = self.relu(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_dim, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(\n",
    "            kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            # initialize the weights\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
    "                )\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.inplanes,\n",
    "                    planes * block.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample)\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "    \n",
    "def resnet18(num_classes):\n",
    "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[2, 2, 2, 2],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for features, targets in data_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float() / num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0469 | Cost: 2.5395\n",
      "Epoch: 001/010 | Batch 0050/0469 | Cost: 0.1715\n",
      "Epoch: 001/010 | Batch 0100/0469 | Cost: 0.1552\n",
      "Epoch: 001/010 | Batch 0150/0469 | Cost: 0.1312\n",
      "Epoch: 001/010 | Batch 0200/0469 | Cost: 0.1527\n",
      "Epoch: 001/010 | Batch 0250/0469 | Cost: 0.1730\n",
      "Epoch: 001/010 | Batch 0300/0469 | Cost: 0.0570\n",
      "Epoch: 001/010 | Batch 0350/0469 | Cost: 0.0641\n",
      "Epoch: 001/010 | Batch 0400/0469 | Cost: 0.1024\n",
      "Epoch: 001/010 | Batch 0450/0469 | Cost: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [08:16<1:14:29, 496.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 0000/0469 | Cost: 0.0313\n",
      "Epoch: 002/010 | Batch 0050/0469 | Cost: 0.0876\n",
      "Epoch: 002/010 | Batch 0100/0469 | Cost: 0.0510\n",
      "Epoch: 002/010 | Batch 0150/0469 | Cost: 0.0415\n",
      "Epoch: 002/010 | Batch 0200/0469 | Cost: 0.1683\n",
      "Epoch: 002/010 | Batch 0250/0469 | Cost: 0.0386\n",
      "Epoch: 002/010 | Batch 0300/0469 | Cost: 0.0842\n",
      "Epoch: 002/010 | Batch 0350/0469 | Cost: 0.1842\n",
      "Epoch: 002/010 | Batch 0400/0469 | Cost: 0.0550\n",
      "Epoch: 002/010 | Batch 0450/0469 | Cost: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [16:20<1:05:12, 489.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 0000/0469 | Cost: 0.4725\n",
      "Epoch: 003/010 | Batch 0050/0469 | Cost: 0.0540\n",
      "Epoch: 003/010 | Batch 0100/0469 | Cost: 0.0447\n",
      "Epoch: 003/010 | Batch 0150/0469 | Cost: 0.0460\n",
      "Epoch: 003/010 | Batch 0200/0469 | Cost: 0.0026\n",
      "Epoch: 003/010 | Batch 0250/0469 | Cost: 0.0555\n",
      "Epoch: 003/010 | Batch 0300/0469 | Cost: 0.0422\n",
      "Epoch: 003/010 | Batch 0350/0469 | Cost: 0.0077\n",
      "Epoch: 003/010 | Batch 0400/0469 | Cost: 0.0503\n",
      "Epoch: 003/010 | Batch 0450/0469 | Cost: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [24:15<56:19, 482.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004/010 | Batch 0000/0469 | Cost: 0.1782\n",
      "Epoch: 004/010 | Batch 0050/0469 | Cost: 0.0081\n",
      "Epoch: 004/010 | Batch 0100/0469 | Cost: 0.0423\n",
      "Epoch: 004/010 | Batch 0150/0469 | Cost: 0.0288\n",
      "Epoch: 004/010 | Batch 0200/0469 | Cost: 0.0048\n",
      "Epoch: 004/010 | Batch 0250/0469 | Cost: 0.0694\n",
      "Epoch: 004/010 | Batch 0300/0469 | Cost: 0.0885\n",
      "Epoch: 004/010 | Batch 0350/0469 | Cost: 0.0533\n",
      "Epoch: 004/010 | Batch 0400/0469 | Cost: 0.0596\n",
      "Epoch: 004/010 | Batch 0450/0469 | Cost: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [31:58<47:29, 474.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005/010 | Batch 0000/0469 | Cost: 0.4053\n",
      "Epoch: 005/010 | Batch 0050/0469 | Cost: 0.0365\n",
      "Epoch: 005/010 | Batch 0100/0469 | Cost: 0.0454\n",
      "Epoch: 005/010 | Batch 0150/0469 | Cost: 0.0069\n",
      "Epoch: 005/010 | Batch 0200/0469 | Cost: 0.0248\n",
      "Epoch: 005/010 | Batch 0250/0469 | Cost: 0.0372\n",
      "Epoch: 005/010 | Batch 0300/0469 | Cost: 0.0391\n",
      "Epoch: 005/010 | Batch 0350/0469 | Cost: 0.0314\n",
      "Epoch: 005/010 | Batch 0400/0469 | Cost: 0.0050\n",
      "Epoch: 005/010 | Batch 0450/0469 | Cost: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [39:25<38:45, 465.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006/010 | Batch 0000/0469 | Cost: 0.5787\n",
      "Epoch: 006/010 | Batch 0050/0469 | Cost: 0.0133\n",
      "Epoch: 006/010 | Batch 0100/0469 | Cost: 0.1367\n",
      "Epoch: 006/010 | Batch 0150/0469 | Cost: 0.0391\n",
      "Epoch: 006/010 | Batch 0200/0469 | Cost: 0.0022\n",
      "Epoch: 006/010 | Batch 0250/0469 | Cost: 0.0092\n",
      "Epoch: 006/010 | Batch 0300/0469 | Cost: 0.0009\n",
      "Epoch: 006/010 | Batch 0350/0469 | Cost: 0.0629\n",
      "Epoch: 006/010 | Batch 0400/0469 | Cost: 0.0131\n",
      "Epoch: 006/010 | Batch 0450/0469 | Cost: 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [47:03<30:49, 462.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007/010 | Batch 0000/0469 | Cost: 0.8569\n",
      "Epoch: 007/010 | Batch 0050/0469 | Cost: 0.0041\n",
      "Epoch: 007/010 | Batch 0100/0469 | Cost: 0.0441\n",
      "Epoch: 007/010 | Batch 0150/0469 | Cost: 0.0049\n",
      "Epoch: 007/010 | Batch 0200/0469 | Cost: 0.0504\n",
      "Epoch: 007/010 | Batch 0250/0469 | Cost: 0.0120\n",
      "Epoch: 007/010 | Batch 0300/0469 | Cost: 0.0468\n",
      "Epoch: 007/010 | Batch 0350/0469 | Cost: 0.0361\n",
      "Epoch: 007/010 | Batch 0400/0469 | Cost: 0.0084\n",
      "Epoch: 007/010 | Batch 0450/0469 | Cost: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [54:41<23:02, 460.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008/010 | Batch 0000/0469 | Cost: 0.3967\n",
      "Epoch: 008/010 | Batch 0050/0469 | Cost: 0.0146\n",
      "Epoch: 008/010 | Batch 0100/0469 | Cost: 0.0276\n",
      "Epoch: 008/010 | Batch 0150/0469 | Cost: 0.0006\n",
      "Epoch: 008/010 | Batch 0200/0469 | Cost: 0.0040\n",
      "Epoch: 008/010 | Batch 0250/0469 | Cost: 0.0036\n",
      "Epoch: 008/010 | Batch 0300/0469 | Cost: 0.0048\n",
      "Epoch: 008/010 | Batch 0350/0469 | Cost: 0.0222\n",
      "Epoch: 008/010 | Batch 0400/0469 | Cost: 0.0056\n",
      "Epoch: 008/010 | Batch 0450/0469 | Cost: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [1:02:17<15:18, 459.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/010 | Batch 0000/0469 | Cost: 0.3907\n",
      "Epoch: 009/010 | Batch 0050/0469 | Cost: 0.0071\n",
      "Epoch: 009/010 | Batch 0100/0469 | Cost: 0.1077\n",
      "Epoch: 009/010 | Batch 0150/0469 | Cost: 0.0003\n",
      "Epoch: 009/010 | Batch 0200/0469 | Cost: 0.0043\n",
      "Epoch: 009/010 | Batch 0250/0469 | Cost: 0.0238\n",
      "Epoch: 009/010 | Batch 0300/0469 | Cost: 0.0383\n",
      "Epoch: 009/010 | Batch 0350/0469 | Cost: 0.0135\n",
      "Epoch: 009/010 | Batch 0400/0469 | Cost: 0.0034\n",
      "Epoch: 009/010 | Batch 0450/0469 | Cost: 0.0319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [1:10:04<07:41, 461.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010/010 | Batch 0000/0469 | Cost: 1.7708\n",
      "Epoch: 010/010 | Batch 0050/0469 | Cost: 0.0116\n",
      "Epoch: 010/010 | Batch 0100/0469 | Cost: 0.0332\n",
      "Epoch: 010/010 | Batch 0150/0469 | Cost: 0.0010\n",
      "Epoch: 010/010 | Batch 0200/0469 | Cost: 0.0042\n",
      "Epoch: 010/010 | Batch 0250/0469 | Cost: 0.0551\n",
      "Epoch: 010/010 | Batch 0300/0469 | Cost: 0.0059\n",
      "Epoch: 010/010 | Batch 0350/0469 | Cost: 0.0019\n",
      "Epoch: 010/010 | Batch 0400/0469 | Cost: 0.0015\n",
      "Epoch: 010/010 | Batch 0450/0469 | Cost: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [1:17:54<00:00, 467.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010/010 | Train: 99.227%\n",
      "Time elapsed: 82.37 min\n",
      "Total Training Time: 82.38 min\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = resnet18(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "            \n",
    "        model.eval()\n",
    "\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.77%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1214b1cd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "\n",
    "nhwc_img = np.transpose(features[0], axes=(1, 2, 0))\n",
    "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
    "plt.imshow(nhw_img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability 7 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logit, probas = model(features.to(DEVICE)[0, None])\n",
    "print('Probability 7 %.2f%%' % (probas[0][7]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
